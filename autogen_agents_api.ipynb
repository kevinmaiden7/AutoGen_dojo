{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\n"
     ]
    }
   ],
   "source": [
    "import autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'tinyllama:1.1b-chat-v1-q2_K',\n",
       "  'base_url': 'http://127.0.0.1:8100/run_tiny_llama_q',\n",
       "  'api_key': 'ollama'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_list_questions = autogen.config_list_from_json(\"model_config_questions.json\")\n",
    "config_list_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'tinyllama:1.1b-chat-v1-q2_K',\n",
       "  'base_url': 'http://127.0.0.1:8100/run_tiny_llama_q',\n",
       "  'api_key': 'ollama'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_list_coder = autogen.config_list_from_json(\"model_config_coder.json\")\n",
    "config_list_coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<autogen.agentchat.conversable_agent.ConversableAgent at 0x21dbc5829f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_questions = autogen.ConversableAgent(\n",
    "    name = \"Agent Questions\",\n",
    "    system_message=\"Your task is to ask question about Python code.\",\n",
    "    llm_config = {\"config_list\": config_list_questions},\n",
    "    code_execution_config = False,\n",
    "    human_input_mode = \"NEVER\",\n",
    "    function_map = None\n",
    ")\n",
    "agent_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<autogen.agentchat.conversable_agent.ConversableAgent at 0x21dbc716f90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_coder = autogen.ConversableAgent(\n",
    "    name = \"Agent Coder\",\n",
    "    system_message=\"Your task is to write Python code.\",\n",
    "    llm_config = {\"config_list\": config_list_coder},\n",
    "    code_execution_config = False,\n",
    "    human_input_mode = \"NEVER\",\n",
    "    function_map = None\n",
    ")\n",
    "agent_coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Generate initial\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[43magent_questions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGive an example of a simple math problem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m reply\n",
      "File \u001b[1;32mc:\\Users\\kevin\\.conda\\envs\\autogen_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:2068\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[1;34m(self, messages, sender, **kwargs)\u001b[0m\n\u001b[0;32m   2066\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[1;32m-> 2068\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[0;32m   2070\u001b[0m         log_event(\n\u001b[0;32m   2071\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2072\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreply_func_executed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2076\u001b[0m             reply\u001b[38;5;241m=\u001b[39mreply,\n\u001b[0;32m   2077\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\kevin\\.conda\\envs\\autogen_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1436\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m   1434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m messages \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1435\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_oai_messages[sender]\n\u001b[1;32m-> 1436\u001b[0m extracted_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_oai_reply_from_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_oai_system_message\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient_cache\u001b[49m\n\u001b[0;32m   1438\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m extracted_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, extracted_response)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\.conda\\envs\\autogen_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1458\u001b[0m, in \u001b[0;36mConversableAgent._generate_oai_reply_from_client\u001b[1;34m(self, llm_client, messages, cache)\u001b[0m\n\u001b[0;32m   1454\u001b[0m \u001b[38;5;66;03m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[0;32m   1455\u001b[0m response \u001b[38;5;241m=\u001b[39m llm_client\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m   1456\u001b[0m     context\u001b[38;5;241m=\u001b[39mmessages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), messages\u001b[38;5;241m=\u001b[39mall_messages, cache\u001b[38;5;241m=\u001b[39mcache, agent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\n\u001b[0;32m   1457\u001b[0m )\n\u001b[1;32m-> 1458\u001b[0m extracted_response \u001b[38;5;241m=\u001b[39m \u001b[43mllm_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_text_or_completion_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extracted_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1461\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracted_response from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mUserWarning\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\.conda\\envs\\autogen_env\\Lib\\site-packages\\autogen\\oai\\client.py:1068\u001b[0m, in \u001b[0;36mOpenAIWrapper.extract_text_or_completion_object\u001b[1;34m(cls, response)\u001b[0m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_text_or_completion_object\u001b[39m(\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28mcls\u001b[39m, response: ModelClient\u001b[38;5;241m.\u001b[39mModelClientResponseProtocol\n\u001b[0;32m   1059\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[List[\u001b[38;5;28mstr\u001b[39m], List[ModelClient\u001b[38;5;241m.\u001b[39mModelClientResponseProtocol\u001b[38;5;241m.\u001b[39mChoice\u001b[38;5;241m.\u001b[39mMessage]]:\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Extract the text or ChatCompletion objects from a completion or chat response.\u001b[39;00m\n\u001b[0;32m   1061\u001b[0m \n\u001b[0;32m   1062\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;124;03m        A list of text, or a list of ChatCompletion objects if function_call/tool_calls are present.\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1068\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage_retrieval_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\.conda\\envs\\autogen_env\\Lib\\site-packages\\autogen\\oai\\client.py:198\u001b[0m, in \u001b[0;36mOpenAIClient.message_retrieval\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [choice\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m choice \u001b[38;5;129;01min\u001b[39;00m choices]  \u001b[38;5;66;03m# type: ignore [union-attr]\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TOOL_ENABLED:\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [  \u001b[38;5;66;03m# type: ignore [return-value]\u001b[39;00m\n\u001b[0;32m    193\u001b[0m         (\n\u001b[0;32m    194\u001b[0m             choice\u001b[38;5;241m.\u001b[39mmessage  \u001b[38;5;66;03m# type: ignore [union-attr]\u001b[39;00m\n\u001b[0;32m    195\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m choice\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mfunction_call \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m choice\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mtool_calls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# type: ignore [union-attr]\u001b[39;00m\n\u001b[0;32m    196\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m choice\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m    197\u001b[0m         )  \u001b[38;5;66;03m# type: ignore [union-attr]\u001b[39;00m\n\u001b[1;32m--> 198\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m choice \u001b[38;5;129;01min\u001b[39;00m choices\n\u001b[0;32m    199\u001b[0m     ]\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [  \u001b[38;5;66;03m# type: ignore [return-value]\u001b[39;00m\n\u001b[0;32m    202\u001b[0m         choice\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;28;01mif\u001b[39;00m choice\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mfunction_call \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m choice\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent  \u001b[38;5;66;03m# type: ignore [union-attr]\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m choice \u001b[38;5;129;01min\u001b[39;00m choices\n\u001b[0;32m    204\u001b[0m     ]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Generate initial\n",
    "reply = agent_questions.generate_reply(messages=[{\"content\": \"Give an example of a simple math problem\", \"role\": \"user\"}])\n",
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
